{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression, Ridge\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier, XGBRegressor, XGBRFClassifier, XGBRFRegressor\n",
    "from copy import deepcopy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data file paths\n",
    "train_raw_path, test_raw_path = r'..\\data\\train_raw.csv', r'..\\data\\test_raw.csv'\n",
    "train_path, test_path = r'..\\data\\train.csv', r'..\\data\\test.csv'\n",
    "\n",
    "# Open csv files\n",
    "train_raw_data = np.loadtxt(train_raw_path, dtype='str', delimiter=',', unpack=True).T\n",
    "test_raw_data = np.loadtxt(test_raw_path, dtype='str', delimiter=',', unpack=True).T\n",
    "\n",
    "N_train, N_test = train_raw_data.shape[0] - 1, test_raw_data.shape[0] - 1\n",
    "num_features = train_raw_data.shape[1] - 2\n",
    "\n",
    "# Initialize arrays for train and test data\n",
    "train_X, train_Y = np.zeros((N_train, train_raw_data.shape[1] - 2)), np.zeros((N_train, 1))\n",
    "test_X = np.zeros((N_test, test_raw_data.shape[1] - 1))\n",
    "\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "formats = \\\n",
    "{ \n",
    "    0:  {'Female': 0, 'Male': 1},\n",
    "    2:  {'No': 0, 'Yes': 1},\n",
    "    3:  {'No': 0, 'Yes': 1},\n",
    "    5:  {'No': 0, 'Yes': 1},\n",
    "    6:  {'No phone service': 0, 'No': 1, 'Yes': 2},\n",
    "    7:  {'No': 0, 'DSL': 1, 'Fiber optic': 2},\n",
    "    8:  {'No internet service': 0, 'No': 1, 'Yes': 2},\n",
    "    9:  {'No internet service': 0, 'No': 1, 'Yes': 2},\n",
    "    10: {'No internet service': 0, 'No': 1, 'Yes': 2},\n",
    "    11: {'No internet service': 0, 'No': 1, 'Yes': 2},\n",
    "    12: {'No internet service': 0, 'No': 1, 'Yes': 2},\n",
    "    13: {'No internet service': 0, 'No': 1, 'Yes': 2},\n",
    "    14: {'Month-to-month': 0, 'One year': 1, 'Two year': 2},\n",
    "    15: {'No': 0, 'Yes': 1},\n",
    "    16: {'Mailed check': 0, 'Bank transfer (automatic)': 1, 'Electronic check': 2, 'Credit card (automatic)': 3},\n",
    "}\n",
    "\n",
    "for i in range(N_train):\n",
    "    train_raw_x, train_raw_y = train_raw_data[i+1, 1:-1], train_raw_data[i+1, -1]\n",
    "    \n",
    "    train_x = np.zeros((num_features))\n",
    "    for j in range(num_features):\n",
    "        if j in formats.keys():\n",
    "            train_x[j] = formats[j][train_raw_x[j]]\n",
    "        else:\n",
    "            if j == 18 and not train_raw_x[j]:              # If 'Total Charges' missing, calculate from 'tenure' and 'Monthly Charges'\n",
    "                train_x[j] = train_x[4] * train_x[17]  \n",
    "            else:\n",
    "                train_x[j] = eval(train_raw_x[j])\n",
    "    \n",
    "    train_y = 1 if train_raw_y == 'Yes' else 0\n",
    "    \n",
    "    \n",
    "    train_X[i], train_Y[i] = train_x, train_y\n",
    "\n",
    "for i in range(N_test):\n",
    "    test_raw_x = test_raw_data[i+1, 1:]\n",
    "    \n",
    "    test_x = np.zeros((num_features))\n",
    "    for j in range(num_features):\n",
    "        if j in formats.keys():\n",
    "            test_x[j] = formats[j][test_raw_x[j]]\n",
    "        else:\n",
    "            if j == 18 and not test_raw_x[j]:              # If 'Total Charges' missing, calculate from 'tenure' and 'Monthly Charges'\n",
    "                test_x[j] = test_x[4] * test_x[17]  \n",
    "            else:\n",
    "                test_x[j] = eval(test_raw_x[j])\n",
    "            \n",
    "    test_X[i] = test_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(model, X, Y, threshold=.5):\n",
    "    Y_pred = model.predict(X)\n",
    "    Y_pred_bin = np.where(Y_pred > threshold, 1, 0)\n",
    "    \n",
    "    return accuracy_score(Y, Y_pred_bin)\n",
    "\n",
    "def cross_validation_xgb(X, Y, n_splits=5, params=None):\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    \n",
    "    train_accs, val_accs = [], []\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, Y_train = X[train_index], Y[train_index]\n",
    "        X_val, Y_val = X[val_index], Y[val_index]\n",
    "        \n",
    "        model = XGBClassifier()\n",
    "        if params:\n",
    "            for param in params.keys():\n",
    "                if param == 'gamma':\n",
    "                    model.set_params(gamma=params['gamma'])\n",
    "                if param == 'min_child_weight':\n",
    "                    model.set_params(min_child_weight=params['min_child_weight'])\n",
    "                if param == 'max_delta_step':\n",
    "                    model.set_params(max_delta_step=params['max_delta_step'])\n",
    "                if param == 'subsample':\n",
    "                    model.set_params(subsample=params['subsample'])\n",
    "                if param == 'max_depth':\n",
    "                    model.set_params(max_depth=params['max_depth'])\n",
    "                    \n",
    "        model.fit(X_train, Y_train)\n",
    "    \n",
    "        train_acc = score(model, X_train, Y_train)\n",
    "        val_acc = score(model, X_val, Y_val)\n",
    "        \n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "    \n",
    "    avg_train_acc, avg_val_acc = np.mean(train_accs), np.mean(val_accs)\n",
    "    \n",
    "    return avg_train_acc, avg_val_acc\n",
    "\n",
    "def plot_data(vals, accs, param, model_type):\n",
    "    plt.figure()\n",
    "\n",
    "    t = 1\n",
    "    plt.plot(vals[::t], accs['train'][::t], marker='.', linewidth=1)\n",
    "    plt.plot(vals[::t], accs['val'][::t], marker='.', linewidth=1)\n",
    "    plt.xlabel(param)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(f'Train and Validation Accuracy vs {param} for {model_type}')\n",
    "    plt.legend(['Train Accuracy', 'Validation Accuracy'], loc='best')\n",
    "    plt.xticks(vals[::5])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Highest val_accuracy = {round(accs['val'][np.argmax(accs['val'])], 4)} with {param} = {vals[np.argmax(accs['val'])]}\")\n",
    "\n",
    "def run_experiment(model_name, param, param_vals):\n",
    "    n_splits = 5\n",
    "    accs = {'train': [], 'val': []}\n",
    "    vals = param_vals\n",
    "\n",
    "    for val in tqdm(vals):\n",
    "        params = \\\n",
    "            {\n",
    "                param: val\n",
    "            }\n",
    "        train_acc, val_acc = cross_validation_xgb(train_X, train_Y, n_splits=n_splits, params=params)\n",
    "\n",
    "        accs['train'].append(train_acc)\n",
    "        accs['val'].append(val_acc)\n",
    "    \n",
    "    plot_data(vals, accs, param, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_experiment('XGBClassifier', 'gamma', range(0, 30))\n",
    "# run_experiment('XGBClassifier', 'min_child_weight', range(74, 150, 2))\n",
    "# run_experiment('XGBClassifier', 'max_delta_step', np.linspace(1, 3, 40))\n",
    "# run_experiment('XGBClassifier', 'max_depth', range(1, 20))\n",
    "# run_experiment('XGBClassifier', 'subsample', [.01] + list(np.linspace(.1, 1, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_xgb(X, Y, n_splits=5, params=None):\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    \n",
    "    train_accs, val_accs = [], []\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, Y_train = X[train_index], Y[train_index]\n",
    "        X_val, Y_val = X[val_index], Y[val_index]\n",
    "        \n",
    "        model = XGBRegressor()\n",
    "        if params:\n",
    "            for param in params.keys():\n",
    "                if param == 'gamma':\n",
    "                    model.set_params(gamma=params['gamma'])\n",
    "                if param == 'min_child_weight':\n",
    "                    model.set_params(min_child_weight=params['min_child_weight'])\n",
    "                if param == 'max_delta_step':\n",
    "                    model.set_params(max_delta_step=params['max_delta_step'])\n",
    "                if param == 'subsample':\n",
    "                    model.set_params(subsample=params['subsample'])\n",
    "                if param == 'max_depth':\n",
    "                    model.set_params(max_depth=params['max_depth'])\n",
    "                    \n",
    "        model.fit(X_train, Y_train)\n",
    "    \n",
    "        train_acc = score(model, X_train, Y_train)\n",
    "        val_acc = score(model, X_val, Y_val)\n",
    "        \n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "    \n",
    "    avg_train_acc, avg_val_acc = np.mean(train_accs), np.mean(val_accs)\n",
    "    \n",
    "    return avg_train_acc, avg_val_acc\n",
    "\n",
    "# run_experiment('XGBRegressor', 'gamma', range(0, 30))\n",
    "# run_experiment('XGBRegressor', 'min_child_weight', range(74, 150, 2))\n",
    "# run_experiment('XGBRegressor', 'max_depth', range(1, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_xgb(X, Y, n_splits=5, params=None):\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    \n",
    "    train_accs, val_accs = [], []\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, Y_train = X[train_index], Y[train_index]\n",
    "        X_val, Y_val = X[val_index], Y[val_index]\n",
    "        \n",
    "        model = XGBRFClassifier()\n",
    "        if params:\n",
    "            for param in params.keys():\n",
    "                if param == 'gamma':\n",
    "                    model.set_params(gamma=params['gamma'])\n",
    "                if param == 'min_child_weight':\n",
    "                    model.set_params(min_child_weight=params['min_child_weight'])\n",
    "                if param == 'max_delta_step':\n",
    "                    model.set_params(max_delta_step=params['max_delta_step'])\n",
    "                if param == 'subsample':\n",
    "                    model.set_params(subsample=params['subsample'])\n",
    "                if param == 'max_depth':\n",
    "                    model.set_params(max_depth=params['max_depth'])\n",
    "                    \n",
    "        model.fit(X_train, Y_train)\n",
    "    \n",
    "        train_acc = score(model, X_train, Y_train)\n",
    "        val_acc = score(model, X_val, Y_val)\n",
    "        \n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "    \n",
    "    avg_train_acc, avg_val_acc = np.mean(train_accs), np.mean(val_accs)\n",
    "    \n",
    "    return avg_train_acc, avg_val_acc\n",
    "\n",
    "# run_experiment('XGBRFClassifier', 'gamma', range(0, 30))\n",
    "# run_experiment('XGBRFClassifier', 'min_child_weight', range(74, 150, 2))\n",
    "# run_experiment('XGBRFClassifier', 'max_delta_step', np.linspace(1, 3, 40))\n",
    "# run_experiment('XGBRFClassifier', 'max_depth', range(1, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation_xgb(X, Y, n_splits=5, params=None):\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    \n",
    "    train_accs, val_accs = [], []\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, Y_train = X[train_index], Y[train_index]\n",
    "        X_val, Y_val = X[val_index], Y[val_index]\n",
    "        \n",
    "        model = XGBRFRegressor()\n",
    "        if params:\n",
    "            for param in params.keys():\n",
    "                if param == 'gamma':\n",
    "                    model.set_params(gamma=params['gamma'])\n",
    "                if param == 'min_child_weight':\n",
    "                    model.set_params(min_child_weight=params['min_child_weight'])\n",
    "                if param == 'max_delta_step':\n",
    "                    model.set_params(max_delta_step=params['max_delta_step'])\n",
    "                if param == 'subsample':\n",
    "                    model.set_params(subsample=params['subsample'])\n",
    "                if param == 'max_depth':\n",
    "                    model.set_params(max_depth=params['max_depth'])\n",
    "                    \n",
    "        model.fit(X_train, Y_train)\n",
    "    \n",
    "        train_acc = score(model, X_train, Y_train)\n",
    "        val_acc = score(model, X_val, Y_val)\n",
    "        \n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "    \n",
    "    avg_train_acc, avg_val_acc = np.mean(train_accs), np.mean(val_accs)\n",
    "    \n",
    "    return avg_train_acc, avg_val_acc\n",
    "\n",
    "# run_experiment('XGBRFRegressor', 'gamma', range(0, 30))\n",
    "# run_experiment('XGBRFRegressor', 'min_child_weight', range(74, 150, 2))\n",
    "# run_experiment('XGBRFRegressor', 'max_depth', range(1, 20))\n",
    "# run_experiment('XGBClassifier', 'subsample', [.01] + list(np.linspace(.1, 1, 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8083005470312813 0.8042277602015254\n"
     ]
    }
   ],
   "source": [
    "def score(model, X, Y, threshold=.5):\n",
    "    Y_pred = model.predict(X)\n",
    "    Y_pred_bin = np.where(Y_pred > threshold, 1, 0)\n",
    "    \n",
    "    return accuracy_score(Y, Y_pred_bin)\n",
    "\n",
    "def cross_validation_xgb(X, Y, n_splits, params=None):\n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    \n",
    "    train_accs, val_accs = [], []\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, Y_train = X[train_index], Y[train_index]\n",
    "        X_val, Y_val = X[val_index], Y[val_index]\n",
    "        \n",
    "        model = XGBClassifier()\n",
    "        if params:\n",
    "            for param in params.keys():\n",
    "                if param == 'gamma':\n",
    "                    model.set_params(gamma=params['gamma'])\n",
    "                if param == 'min_child_weight':\n",
    "                    model.set_params(min_child_weight=params['min_child_weight'])\n",
    "                if param == 'max_delta_step':\n",
    "                    model.set_params(max_delta_step=params['max_delta_step'])\n",
    "                if param == 'subsample':\n",
    "                    model.set_params(subsample=params['subsample'])\n",
    "                if param == 'max_depth':\n",
    "                    model.set_params(max_depth=params['max_depth'])\n",
    "                    \n",
    "        model.fit(X_train, Y_train)\n",
    "    \n",
    "        train_acc = score(model, X_train, Y_train)\n",
    "        val_acc = score(model, X_val, Y_val)\n",
    "        \n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "    \n",
    "    avg_train_acc, avg_val_acc = np.mean(train_accs), np.mean(val_accs)\n",
    "    \n",
    "    return avg_train_acc, avg_val_acc\n",
    "\n",
    "n_splits = 5\n",
    "params = \\\n",
    "    {\n",
    "        'gamma': 6,\n",
    "        'min_child_weight': 116,\n",
    "        'max_delta_step': 2.0769,\n",
    "        'max_depth': 4\n",
    "    }\n",
    "\n",
    "train_acc, val_acc = cross_validation_xgb(train_X, train_Y, n_splits, params=params)\n",
    "\n",
    "print(train_acc, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.838 (0.009)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "model = XGBRFClassifier(objective='binary:logistic', device='cuda')\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "# cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1001)\n",
    "\n",
    "n_scores = cross_val_score(model, train_X, train_Y, scoring='roc_auc', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8203256597417181\n"
     ]
    }
   ],
   "source": [
    "model = XGBRFClassifier(objective='binary:logistic', device='cuda')\n",
    "model.fit(train_X, train_Y)\n",
    "print(model.score(train_X, train_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8203256597417181\n",
      "[0.8319212  0.14630349 0.18248063 ... 0.5132345  0.0959857  0.77113104]\n",
      "[1 0 0 ... 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "model = XGBRFClassifier(objective='binary:logistic', device='cuda')\n",
    "model.fit(train_X, train_Y)\n",
    "print(model.score(train_X, train_Y))\n",
    "print(model.predict_proba(train_X)[:, 1])\n",
    "print(model.predict(train_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def generate_submission(file_path, customer_IDs, test_Y):    \n",
    "    file = open(file_path, 'w')\n",
    "    file.write('ID, TARGET\\n')\n",
    "    for i, id in enumerate(customer_IDs):\n",
    "        line = f\"{id}, {test_Y[i]}\"\n",
    "        if i != len(customer_IDs) - 1:\n",
    "            line += '\\n'\n",
    "            \n",
    "        file.write(line)\n",
    "    file.close()\n",
    "\n",
    "model = XGBRFClassifier(objective='binary:logistic', device='cuda')\n",
    "\n",
    "model.fit(train_X, train_Y)\n",
    "\n",
    "test_Y = model.predict_proba(test_X)[:, 1]\n",
    "generate_submission('..\\submissions\\\\xgbrfclf_1.csv', test_raw_data.T[0, 1:], test_Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
